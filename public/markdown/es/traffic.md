Construir un sistema de detecci√≥n de se√±ales de tr√°fico era algo que hab√≠a querido abordar desde hace tiempo. Era una oportunidad para **combinar t√©cnicas modernas de detecci√≥n, experimentar con optimizaciones en tiempo real y crear algo que realmente pudiera ser √∫til** en escenarios del mundo real. Hab√≠a trabajado antes en sistemas de detecci√≥n m√°s simples, como el clasificador de n√∫meros MNIST que hice en la universidad, pero eso solo era una prueba de concepto.

Esta vez quer√≠a construir un **pipeline** que pudiera manejar im√°genes y secuencias de video de manera fluida. En esta publicaci√≥n, voy a explicar el proceso de creaci√≥n de mi sistema de detecci√≥n de se√±ales de tr√°fico usando **YOLO**, **TensorFlow** y varias t√©cnicas de optimizaci√≥n, junto con los desaf√≠os que enfrent√© y las soluciones que encontr√©.

## ¬øPor qu√© un enfoque de dos etapas?

Decid√≠ usar un **pipeline de detecci√≥n de dos etapas** porque era mi primer proyecto usando YOLO y quer√≠a aprender c√≥mo funciona. No hab√≠a trabajado mucho en visi√≥n por computadora y no ten√≠a mucha experiencia con detecci√≥n de objetos, as√≠ que decid√≠ mezclar lo que ya sab√≠a (construir Redes Neuronales Convolucionales) con lo que quer√≠a aprender (YOLO). La primera etapa usa YOLO para detectar r√°pidamente posibles se√±ales de tr√°fico en el cuadro, mientras que la segunda etapa usa un clasificador CNN personalizado para identificar exactamente qu√© tipo de se√±al es.

La alternativa habr√≠a sido entrenar YOLO para detectar directamente las 99 clases diferentes de se√±ales de tr√°fico, pero eso habr√≠a requerido un conjunto de datos anotados mucho m√°s grande y probablemente resultar√≠a en una menor precisi√≥n para se√±ales que se parecen entre s√≠ (adem√°s, preparar un conjunto de datos as√≠ habr√≠a requerido mucho tiempo, y los pocos conjuntos de datos existentes listos para YOLO no eran exactamente lo que quer√≠a).

## Entrenamiento del clasificador

El modelo de clasificaci√≥n fue en el que pas√© la mayor parte del tiempo afinando. Trabajar con **99 clases diferentes de se√±ales de tr√°fico** del conjunto de datos espa√±ol significaba lidiar con se√±ales que pueden parecer muy similares en resoluciones bajas. Aqu√≠ est√° la arquitectura en la que me qued√© despu√©s de mucha experimentaci√≥n:

```python
num_classes = 99
data_augmentation = tf.keras.Sequential([
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

model = models.Sequential([
    layers.InputLayer(input_shape=(128, 128, 3)),
    layers.Rescaling(1./255),
    data_augmentation,
    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(2),
    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(2),
    layers.Conv2D(128, 3, activation='relu'),
    layers.MaxPooling2D(2),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])
```

## Retos del tiempo real

Hacer que el sistema funcione de manera fluida en video fue lo m√°s interesante. Mi primer intento procesaba los cuadros secuencialmente, lo que resultaba en un rendimiento muy lento, tal vez 5-10 FPS incluso en una GPU decente. Ah√≠ fue cuando me di cuenta de que necesitaba ser creativo con las optimizaciones.

El avance vino al implementar procesamiento por lotes y multihilo. En lugar de clasificar cada se√±al detectada individualmente, recolecto todos los recortes de un cuadro y los proceso como un lote. Este simple cambio por s√≠ solo me dio una mejora de 3-4x en velocidad, porque las GPUs son mucho m√°s eficientes procesando lotes que im√°genes individuales.

Tambi√©n a√±ad√≠ un patr√≥n productor-consumidor con hilos para mantener la GPU ocupada mientras manejaba las operaciones de entrada/salida de video. El hilo principal lee los cuadros y muestra los resultados, mientras que los hilos de trabajo manejan la detecci√≥n y clasificaci√≥n real. Esto mantiene todo funcionando sin interrupciones.

## Restricciones del mundo real 

Algo que qued√≥ claro desde el principio es que la precisi√≥n en laboratorio no siempre se traduce en un buen desempe√±o en el mundo real. Se√±ales que el modelo clasificaba perfectamente en el conjunto de prueba a veces se mal clasificaban en video real debido a desenfoque de movimiento, poca luz u oclusiones parciales.

Para manejar esto, a√±ad√≠ umbrales de confianza en ambas etapas: YOLO debe estar suficientemente seguro de haber encontrado una se√±al, y el clasificador debe estar seguro del tipo de se√±al. Tambi√©n filtro detecciones demasiado peque√±as, ya que suelen ser falsos positivos o se√±ales demasiado lejanas para clasificarlas de manera fiable.

## Mejoras de rendimiento

M√°s all√° de las mejoras algor√≠tmicas, implement√© varias optimizaciones t√©cnicas para exprimir m√°s rendimiento:

- **Entrenamiento de precisi√≥n mixta**: Usar float16 cuando es posible aceler√≥ significativamente tanto el entrenamiento como la inferencia.

- **Compilaci√≥n JIT de TensorFlow**: Esto dio un 10-15% de mejora adicional en el rendimiento del clasificador.


## Algunos resultados

<div style="background-color: black; display: flex; align-items: center; justify-content: center;">
  <video controls width="90%" ><source src="/source/traffic_detection.mp4"></video>
</div>

## Sobre los resultados

El video deja claros algunos problemas del pipeline. Para evitar que el video se detuviera mientras se realizaba la inferencia, us√© el modelo de hilos productor/consumidor que mencion√© en la secci√≥n de desaf√≠os. Este enfoque permiti√≥ un video fluido (importante para la experiencia del usuario) a costa de algo de latencia en la inferencia. Por eso algunas cajas de detecci√≥n parecen ‚Äúretrasadas‚Äù respecto a las se√±ales reales. Aunque pueda parecer que la detecci√≥n falla, simplemente la se√±al se ha ‚Äúmovido‚Äù en relaci√≥n a la c√°mara y al tiempo de la inferencia.

El c√≥digo completo est√° disponible en mi GitHub, y siempre estoy feliz de discutir mejoras o responder preguntas sobre la implementaci√≥n! üòÑ



